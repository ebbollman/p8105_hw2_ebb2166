---
title: "Homework 2"
author: E. Brennan Bollman
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

##### Step 1: Read the Mr. Trashwheel dataset, with clean names, omitting non-data entries and values that are not dumpster-specific.

```{r}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

##### Step 2: Read the precipitation data for 2017 and 2018. 

```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

##### Step 3: Combine annual precipitation. Convert month from dbl to character variable.

```{r}
precip_df = 
  bind_rows(precip_2018, precip_2017)

month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

left_join(precip_df, month_df, by = "month") %>% 
  select(year, month_name, total, -month)
```

##### Step 4: Describe datasets.

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and amount trash collected, including specific kinds of trash. There are a total of `r nrow(trashwheel_df)` observations on this data for the dumpster. Additional data include monthly precipitation data for the years `r precip_df %>% pull(year) %>% min()` to `r precip_df %>% pull(year) %>% max()` and include observations on `r nrow(precip_df)`. The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`. The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

## Problem 2

##### Step 1: Read the NYC Transit data and clean, describe.

```{r}
nyctransit_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, YES = "TRUE", NO = "FALSE")) %>% 
  mutate(entry = as.logical(entry))
```

This dataset describes NYC subway station locations, the lines and routes running through those stations, and various parameters such as if the station offers ticket vending, the type of entrance to the station, and whether the is ADA compliant. Data were first imported, pertinent variables selected, and some variable types transformed. Data are presented on `r nrow(nyctransit_df)` observations for `r ncol(nyctransit_df)` variables. These data are not yet tidy, however, in part because the number of routes passing each station and names of those routes are presented across 11 variable columns.

##### Step 2: Analyze data.

There are `r nrow(distinct(nyctransit_df, line, station_name))` distinct stations in this dataset.
There are `r nyctransit_df %>% filter(ada == "TRUE") %>% distinct(line, station_name) %>% count()` distinct stations that are ADA compliant. Of the `r nyctransit_df %>% filter(vending == "NO") %>% count()` station entrances/exits that do not have vending services, `r nyctransit_df %>% filter(vending == "NO" & entry == "TRUE") %>% count()` allow entry (`r 69/183 * 100` percent).

##### Step 3: Reformat dataset such that route number and name are distinct, further analyze.

```{r}
nyctransit_tidy_df =
  nyctransit_df %>%
  mutate_at(vars(route1:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number"
  ) %>% 
  drop_na(route_number)
```

There are `r nyctransit_tidy_df %>% filter(route_number == "A") %>% distinct(line, station_name) %>% count()` stations that serve the A train. Of these stations, only `r nyctransit_tidy_df %>% filter(route_number == "A" & ada == "TRUE") %>% distinct(line, station_name) %>% count()` are ADA compliant.

## Problem 3

##### Step 1: Read and clean pols-month dataset. 

```{r}
pols_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(
    mon,
    into = c("year", "month", "date"),
    sep = "-"
  ) %>% 
  mutate_at(vars(year:date), as.integer)

month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

left_join(pols_df, month_df, by = "month") %>% 
  select(year, month_name, everything()) %>%
  mutate_at(vars(prez_gop, prez_dem), as.character) %>% 
  mutate(
    president = case_when(
      prez_dem == 1 ~ "dem",
      prez_gop == 1 ~ "gop",
      prez_gop == 2 ~ "gop"
    )
  ) %>% 
select(-month, -date, -prez_gop, -prez_dem) %>% 
    mutate(month = month_name) %>% 
  select(year, month, everything()) %>% 
  select(-month_name)
```

Cleaning steps included: separating date, convert month to name instead of number, drop date; creating character president variable to replace numerical GOP and DEM specific president variables; dropping unecessary variables.

##### Step 2: Read and clean the snp dataset.

```{r}
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(
    date,
    into = c("month", "day", "year"),
    sep = "/"
  ) %>% 
  mutate_at(vars(month:year), as.integer)

month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

left_join(snp_df, month_df, by = "month") %>% 
  select(year, month_name, close, -month, -day) %>%
  arrange(year, month_name) %>% 
  mutate(month = month_name) %>% 
  select(year, month, close)
```

Cleaning steps included: separating date, converting month to its character name instead of number, dropping the day variable, and then arranging by year and month. This snp_df now shares variable names 'year' and 'month_name' with the pols_df. 

##### Step 3: read and clean the unemployment dataset.

```{r}
unemp_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment") %>% 
  mutate(month = recode(month,
         `jan` = "January",
         `feb` = "February",
         `mar` = "March",
         `apr` = "April",
         `may` = "May",
         `jun` = "June",
         `jul` = "July",
         `aug` = "August",
         `sept` = "September",
         `oct` = "October",
         `nov` = "November",
         `dec` = "December")) %>% 
  mutate(year = as.integer(year))
```

Cleaning steps included: using pivot_longer to make the data tidy such that month is a variable. Additionally, had to recode month_name values to match format of the pols_df and snp_df in preparation for joining. 

##### Step 4: Merge the datasets.

Could not get this to work. Attempted code chunk below. Appeared as though my chunks in steps 1-3 hadn't saved somehow---despite running each individually in environment and everything appearing to work. Initial variable 'month_name' wasn't being recognized in attempted join so edited code chunks above to mutate back to 'month'. Am unclear where I went wrong. Will try to get help to learn for next time. 

pols_snp_df = 
  left_join(pols_df, snp_df, by = c("year", "month"))

final_df =
  left_join(pols_snp_df, unemp_df, by = c("year", "month"))
